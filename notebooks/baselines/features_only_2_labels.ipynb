{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline training on network and other features besides text content"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Data paths\n",
    "TRAIN = \"../../data/prepared/train_features.pkl\"\n",
    "VAL = \"../../data/prepared/val_features.pkl\"\n",
    "TEST = \"../../data/prepared/test_features.pkl\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_df = pd.read_pickle(TRAIN)\n",
    "train_df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159544 entries, 0 to 173184\n",
      "Data columns (total 51 columns):\n",
      " #   Column                                Non-Null Count   Dtype  \n",
      "---  ------                                --------------   -----  \n",
      " 0   id_str                                159544 non-null  object \n",
      " 1   entities.urls                         159544 non-null  int64  \n",
      " 2   entities.media                        159544 non-null  int64  \n",
      " 3   user_in_net                           159544 non-null  int64  \n",
      " 4   has_covid_keyword                     159544 non-null  int64  \n",
      " 5   tweets_keywords_3_in_degree           159544 non-null  float64\n",
      " 6   tweets_keywords_3_out_degree          159544 non-null  float64\n",
      " 7   tweets_keywords_3_in_strength         159544 non-null  float64\n",
      " 8   tweets_keywords_3_out_strength        159544 non-null  float64\n",
      " 9   tweets_keywords_3_eigenvector_in      159544 non-null  float64\n",
      " 10  tweets_keywords_3_eigenvector_out     159544 non-null  float64\n",
      " 11  tweets_keywords_3_katz_in             159544 non-null  float64\n",
      " 12  tweets_keywords_3_katz_out            159544 non-null  float64\n",
      " 13  tweets_keywords_3_clustering          159544 non-null  float64\n",
      " 14  users_mention_in_degree               159544 non-null  float64\n",
      " 15  users_mention_out_degree              159544 non-null  float64\n",
      " 16  users_mention_in_strength             159544 non-null  float64\n",
      " 17  users_mention_out_strength            159544 non-null  float64\n",
      " 18  users_mention_eigenvector_in          159544 non-null  float64\n",
      " 19  users_mention_eigenvector_out         159544 non-null  float64\n",
      " 20  users_mention_katz_in                 159544 non-null  float64\n",
      " 21  users_mention_katz_out                159544 non-null  float64\n",
      " 22  users_mention_clustering              159544 non-null  float64\n",
      " 23  folowing_users_graph_in_degree        159544 non-null  float64\n",
      " 24  folowing_users_graph_out_degree       159544 non-null  float64\n",
      " 25  folowing_users_graph_in_strength      159544 non-null  float64\n",
      " 26  folowing_users_graph_out_strength     159544 non-null  float64\n",
      " 27  folowing_users_graph_eigenvector_in   159544 non-null  float64\n",
      " 28  folowing_users_graph_eigenvector_out  159544 non-null  float64\n",
      " 29  folowing_users_graph_katz_in          159544 non-null  float64\n",
      " 30  folowing_users_graph_katz_out         159544 non-null  float64\n",
      " 31  folowing_users_graph_clustering       159544 non-null  float64\n",
      " 32  users_reply_in_degree                 159544 non-null  float64\n",
      " 33  users_reply_out_degree                159544 non-null  float64\n",
      " 34  users_reply_in_strength               159544 non-null  float64\n",
      " 35  users_reply_out_strength              159544 non-null  float64\n",
      " 36  users_reply_eigenvector_in            159544 non-null  float64\n",
      " 37  users_reply_eigenvector_out           159544 non-null  float64\n",
      " 38  users_reply_katz_in                   159544 non-null  float64\n",
      " 39  users_reply_katz_out                  159544 non-null  float64\n",
      " 40  users_reply_clustering                159544 non-null  float64\n",
      " 41  retweet_label                         159544 non-null  int64  \n",
      " 42  user.followers_isna                   159544 non-null  int64  \n",
      " 43  users_mention_isna                    159544 non-null  float64\n",
      " 44  following_users_isna                  159544 non-null  int64  \n",
      " 45  users_reply_isna                      159544 non-null  float64\n",
      " 46  log1p_num_hashtags                    159544 non-null  float64\n",
      " 47  log1p_followers_count                 159544 non-null  float64\n",
      " 48  log1p_friends_count                   159544 non-null  float64\n",
      " 49  log1p_statuses_count                  159544 non-null  float64\n",
      " 50  log1p_num_mentioned                   159544 non-null  float64\n",
      "dtypes: float64(43), int64(7), object(1)\n",
      "memory usage: 63.3+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_df_labels = train_df.retweet_label\n",
    "train_df.drop([\"retweet_label\", \"id_str\"], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "val_df = pd.read_pickle(VAL)\n",
    "val_df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19943 entries, 173185 to 194714\n",
      "Data columns (total 51 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   id_str                                19943 non-null  object \n",
      " 1   entities.urls                         19943 non-null  int64  \n",
      " 2   entities.media                        19943 non-null  int64  \n",
      " 3   user_in_net                           19943 non-null  int64  \n",
      " 4   has_covid_keyword                     19943 non-null  int64  \n",
      " 5   tweets_keywords_3_in_degree           19943 non-null  float64\n",
      " 6   tweets_keywords_3_out_degree          19943 non-null  float64\n",
      " 7   tweets_keywords_3_in_strength         19943 non-null  float64\n",
      " 8   tweets_keywords_3_out_strength        19943 non-null  float64\n",
      " 9   tweets_keywords_3_eigenvector_in      19943 non-null  float64\n",
      " 10  tweets_keywords_3_eigenvector_out     19943 non-null  float64\n",
      " 11  tweets_keywords_3_katz_in             19943 non-null  float64\n",
      " 12  tweets_keywords_3_katz_out            19943 non-null  float64\n",
      " 13  tweets_keywords_3_clustering          19943 non-null  float64\n",
      " 14  users_mention_in_degree               19943 non-null  float64\n",
      " 15  users_mention_out_degree              19943 non-null  float64\n",
      " 16  users_mention_in_strength             19943 non-null  float64\n",
      " 17  users_mention_out_strength            19943 non-null  float64\n",
      " 18  users_mention_eigenvector_in          19943 non-null  float64\n",
      " 19  users_mention_eigenvector_out         19943 non-null  float64\n",
      " 20  users_mention_katz_in                 19943 non-null  float64\n",
      " 21  users_mention_katz_out                19943 non-null  float64\n",
      " 22  users_mention_clustering              19943 non-null  float64\n",
      " 23  folowing_users_graph_in_degree        19943 non-null  float64\n",
      " 24  folowing_users_graph_out_degree       19943 non-null  float64\n",
      " 25  folowing_users_graph_in_strength      19943 non-null  float64\n",
      " 26  folowing_users_graph_out_strength     19943 non-null  float64\n",
      " 27  folowing_users_graph_eigenvector_in   19943 non-null  float64\n",
      " 28  folowing_users_graph_eigenvector_out  19943 non-null  float64\n",
      " 29  folowing_users_graph_katz_in          19943 non-null  float64\n",
      " 30  folowing_users_graph_katz_out         19943 non-null  float64\n",
      " 31  folowing_users_graph_clustering       19943 non-null  float64\n",
      " 32  users_reply_in_degree                 19943 non-null  float64\n",
      " 33  users_reply_out_degree                19943 non-null  float64\n",
      " 34  users_reply_in_strength               19943 non-null  float64\n",
      " 35  users_reply_out_strength              19943 non-null  float64\n",
      " 36  users_reply_eigenvector_in            19943 non-null  float64\n",
      " 37  users_reply_eigenvector_out           19943 non-null  float64\n",
      " 38  users_reply_katz_in                   19943 non-null  float64\n",
      " 39  users_reply_katz_out                  19943 non-null  float64\n",
      " 40  users_reply_clustering                19943 non-null  float64\n",
      " 41  retweet_label                         19943 non-null  int64  \n",
      " 42  user.followers_isna                   19943 non-null  int64  \n",
      " 43  users_mention_isna                    19943 non-null  float64\n",
      " 44  following_users_isna                  19943 non-null  int64  \n",
      " 45  users_reply_isna                      19943 non-null  float64\n",
      " 46  log1p_num_hashtags                    19943 non-null  float64\n",
      " 47  log1p_followers_count                 19943 non-null  float64\n",
      " 48  log1p_friends_count                   19943 non-null  float64\n",
      " 49  log1p_statuses_count                  19943 non-null  float64\n",
      " 50  log1p_num_mentioned                   19943 non-null  float64\n",
      "dtypes: float64(43), int64(7), object(1)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "val_df_labels = val_df.retweet_label\n",
    "val_df.drop([\"retweet_label\", \"id_str\"], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "test_df = pd.read_pickle(TEST)\n",
    "test_df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19944 entries, 194715 to 214669\n",
      "Data columns (total 51 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   id_str                                19944 non-null  object \n",
      " 1   entities.urls                         19944 non-null  int64  \n",
      " 2   entities.media                        19944 non-null  int64  \n",
      " 3   user_in_net                           19944 non-null  int64  \n",
      " 4   has_covid_keyword                     19944 non-null  int64  \n",
      " 5   tweets_keywords_3_in_degree           19944 non-null  float64\n",
      " 6   tweets_keywords_3_out_degree          19944 non-null  float64\n",
      " 7   tweets_keywords_3_in_strength         19944 non-null  float64\n",
      " 8   tweets_keywords_3_out_strength        19944 non-null  float64\n",
      " 9   tweets_keywords_3_eigenvector_in      19944 non-null  float64\n",
      " 10  tweets_keywords_3_eigenvector_out     19944 non-null  float64\n",
      " 11  tweets_keywords_3_katz_in             19944 non-null  float64\n",
      " 12  tweets_keywords_3_katz_out            19944 non-null  float64\n",
      " 13  tweets_keywords_3_clustering          19944 non-null  float64\n",
      " 14  users_mention_in_degree               19944 non-null  float64\n",
      " 15  users_mention_out_degree              19944 non-null  float64\n",
      " 16  users_mention_in_strength             19944 non-null  float64\n",
      " 17  users_mention_out_strength            19944 non-null  float64\n",
      " 18  users_mention_eigenvector_in          19944 non-null  float64\n",
      " 19  users_mention_eigenvector_out         19944 non-null  float64\n",
      " 20  users_mention_katz_in                 19944 non-null  float64\n",
      " 21  users_mention_katz_out                19944 non-null  float64\n",
      " 22  users_mention_clustering              19944 non-null  float64\n",
      " 23  folowing_users_graph_in_degree        19944 non-null  float64\n",
      " 24  folowing_users_graph_out_degree       19944 non-null  float64\n",
      " 25  folowing_users_graph_in_strength      19944 non-null  float64\n",
      " 26  folowing_users_graph_out_strength     19944 non-null  float64\n",
      " 27  folowing_users_graph_eigenvector_in   19944 non-null  float64\n",
      " 28  folowing_users_graph_eigenvector_out  19944 non-null  float64\n",
      " 29  folowing_users_graph_katz_in          19944 non-null  float64\n",
      " 30  folowing_users_graph_katz_out         19944 non-null  float64\n",
      " 31  folowing_users_graph_clustering       19944 non-null  float64\n",
      " 32  users_reply_in_degree                 19944 non-null  float64\n",
      " 33  users_reply_out_degree                19944 non-null  float64\n",
      " 34  users_reply_in_strength               19944 non-null  float64\n",
      " 35  users_reply_out_strength              19944 non-null  float64\n",
      " 36  users_reply_eigenvector_in            19944 non-null  float64\n",
      " 37  users_reply_eigenvector_out           19944 non-null  float64\n",
      " 38  users_reply_katz_in                   19944 non-null  float64\n",
      " 39  users_reply_katz_out                  19944 non-null  float64\n",
      " 40  users_reply_clustering                19944 non-null  float64\n",
      " 41  retweet_label                         19944 non-null  int64  \n",
      " 42  user.followers_isna                   19944 non-null  int64  \n",
      " 43  users_mention_isna                    19944 non-null  float64\n",
      " 44  following_users_isna                  19944 non-null  int64  \n",
      " 45  users_reply_isna                      19944 non-null  float64\n",
      " 46  log1p_num_hashtags                    19944 non-null  float64\n",
      " 47  log1p_followers_count                 19944 non-null  float64\n",
      " 48  log1p_friends_count                   19944 non-null  float64\n",
      " 49  log1p_statuses_count                  19944 non-null  float64\n",
      " 50  log1p_num_mentioned                   19944 non-null  float64\n",
      "dtypes: float64(43), int64(7), object(1)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "test_df_labels = test_df.retweet_label\n",
    "test_df.drop([\"retweet_label\", \"id_str\"], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "clf = MLPClassifier(\n",
    "    max_iter=50,\n",
    "    hidden_layer_sizes=(512,),\n",
    "    random_state=1,\n",
    "    verbose=True,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=5,\n",
    "    learning_rate_init=0.001,\n",
    "    batch_size=256)\n",
    "clf.fit(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 1, loss = 0.61166617\n",
      "Validation score: 0.664933\n",
      "Iteration 2, loss = 0.59752586\n",
      "Validation score: 0.671388\n",
      "Iteration 3, loss = 0.59348806\n",
      "Validation score: 0.667941\n",
      "Iteration 4, loss = 0.58964721\n",
      "Validation score: 0.679160\n",
      "Iteration 5, loss = 0.58725558\n",
      "Validation score: 0.671890\n",
      "Iteration 6, loss = 0.58548920\n",
      "Validation score: 0.677907\n",
      "Iteration 7, loss = 0.58373419\n",
      "Validation score: 0.681416\n",
      "Iteration 8, loss = 0.58216362\n",
      "Validation score: 0.682482\n",
      "Iteration 9, loss = 0.58083020\n",
      "Validation score: 0.673394\n",
      "Iteration 10, loss = 0.57973822\n",
      "Validation score: 0.680100\n",
      "Iteration 11, loss = 0.57859947\n",
      "Validation score: 0.681354\n",
      "Iteration 12, loss = 0.57749225\n",
      "Validation score: 0.683924\n",
      "Iteration 13, loss = 0.57645485\n",
      "Validation score: 0.684425\n",
      "Iteration 14, loss = 0.57565323\n",
      "Validation score: 0.683297\n",
      "Iteration 15, loss = 0.57460824\n",
      "Validation score: 0.683046\n",
      "Iteration 16, loss = 0.57398114\n",
      "Validation score: 0.684049\n",
      "Iteration 17, loss = 0.57308703\n",
      "Validation score: 0.687183\n",
      "Iteration 18, loss = 0.57191888\n",
      "Validation score: 0.684801\n",
      "Iteration 19, loss = 0.57145430\n",
      "Validation score: 0.684989\n",
      "Iteration 20, loss = 0.57086213\n",
      "Validation score: 0.681103\n",
      "Iteration 21, loss = 0.57006409\n",
      "Validation score: 0.685992\n",
      "Iteration 22, loss = 0.56967489\n",
      "Validation score: 0.682921\n",
      "Iteration 23, loss = 0.56852862\n",
      "Validation score: 0.684488\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(batch_size=256, early_stopping=True, hidden_layer_sizes=(512,),\n",
       "              max_iter=50, n_iter_no_change=5, random_state=1, verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "clf.best_validation_score_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.68718270134754"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "clf.score(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6984405555834128"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "clf.score(val_df.values, val_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6815423958281102"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "val_predictions = clf.predict(val_df.values)\n",
    "val_predictions.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(19943,)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "out = classification_report(val_df_labels.values, val_predictions, output_dict=False)\n",
    "print(out)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72     10954\n",
      "           1       0.67      0.58      0.62      8989\n",
      "\n",
      "    accuracy                           0.68     19943\n",
      "   macro avg       0.68      0.67      0.67     19943\n",
      "weighted avg       0.68      0.68      0.68     19943\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLP Classifier (2)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "clf_2 = MLPClassifier(\n",
    "    max_iter=50,\n",
    "    hidden_layer_sizes=(1000,50,30),\n",
    "    random_state=1,\n",
    "    verbose=True,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=5,\n",
    "    learning_rate_init=0.001,\n",
    "    batch_size=32)\n",
    "clf_2.fit(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 1, loss = 0.61074513\n",
      "Validation score: 0.681605\n",
      "Iteration 2, loss = 0.59739695\n",
      "Validation score: 0.680414\n",
      "Iteration 3, loss = 0.59217806\n",
      "Validation score: 0.687183\n",
      "Iteration 4, loss = 0.58874952\n",
      "Validation score: 0.685553\n",
      "Iteration 5, loss = 0.58599592\n",
      "Validation score: 0.685553\n",
      "Iteration 6, loss = 0.58403848\n",
      "Validation score: 0.685553\n",
      "Iteration 7, loss = 0.58234483\n",
      "Validation score: 0.687997\n",
      "Iteration 8, loss = 0.58047310\n",
      "Validation score: 0.687496\n",
      "Iteration 9, loss = 0.57881630\n",
      "Validation score: 0.691257\n",
      "Iteration 10, loss = 0.57701676\n",
      "Validation score: 0.688812\n",
      "Iteration 11, loss = 0.57592531\n",
      "Validation score: 0.690128\n",
      "Iteration 12, loss = 0.57453660\n",
      "Validation score: 0.685428\n",
      "Iteration 13, loss = 0.57346691\n",
      "Validation score: 0.691257\n",
      "Iteration 14, loss = 0.57216164\n",
      "Validation score: 0.688938\n",
      "Iteration 15, loss = 0.57178475\n",
      "Validation score: 0.685992\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(batch_size=32, early_stopping=True,\n",
       "              hidden_layer_sizes=(1000, 50, 30), max_iter=50,\n",
       "              n_iter_no_change=5, random_state=1, verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "clf_2.best_validation_score_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6912566593544344"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "clf_2.score(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6986912701198416"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "clf_2.score(val_df.values, val_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6793361079075365"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "val_predictions = clf_2.predict(val_df.values)\n",
    "val_predictions.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(19943,)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "out = classification_report(val_df_labels.values, val_predictions, output_dict=False)\n",
    "print(out)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.72     10954\n",
      "           1       0.67      0.57      0.62      8989\n",
      "\n",
      "    accuracy                           0.68     19943\n",
      "   macro avg       0.68      0.67      0.67     19943\n",
      "weighted avg       0.68      0.68      0.68     19943\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=25,\n",
    "    min_samples_split=0.00002,\n",
    "    min_samples_leaf=0.00002,\n",
    "    random_state=1,\n",
    "    verbose=True,\n",
    "    n_jobs=-1,\n",
    "    max_samples=0.4,\n",
    "    max_features=0.2,\n",
    "    oob_score=True,\n",
    "    class_weight=\"balanced\",\n",
    "    min_impurity_decrease=0.00008\n",
    "    )\n",
    "rf.fit(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=25, max_features=0.2,\n",
       "                       max_samples=0.4, min_impurity_decrease=8e-05,\n",
       "                       min_samples_leaf=2e-05, min_samples_split=2e-05,\n",
       "                       n_estimators=200, n_jobs=-1, oob_score=True,\n",
       "                       random_state=1, verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "rf.score(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=24)]: Done 200 out of 200 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6902609938324225"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "rf.score(val_df.values, val_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6780323923181066"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "rf_val_predictions = rf.predict(val_df.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=24)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "out = classification_report(val_df_labels.values, rf_val_predictions, output_dict=False, digits=3)\n",
    "print(out)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.723     0.671     0.696     10954\n",
      "           1      0.631     0.687     0.658      8989\n",
      "\n",
      "    accuracy                          0.678     19943\n",
      "   macro avg      0.677     0.679     0.677     19943\n",
      "weighted avg      0.682     0.678     0.679     19943\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dummy classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "s_dummy = DummyClassifier(strategy=\"stratified\", random_state=1)\n",
    "s_dummy.fit(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=1, strategy='stratified')"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "dummy_val_predictions = s_dummy.predict(val_df.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "out = classification_report(val_df_labels.values, dummy_val_predictions, output_dict=False)\n",
    "print(out)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.58      0.56     10954\n",
      "           1       0.45      0.41      0.43      8989\n",
      "\n",
      "    accuracy                           0.51     19943\n",
      "   macro avg       0.50      0.50      0.50     19943\n",
      "weighted avg       0.50      0.51      0.50     19943\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15267cfa9f25b6ca31c547cf72167e122f3ae1ce2ab22c3e1aaf6fd39ae5e059"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('infocov_retweet': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}