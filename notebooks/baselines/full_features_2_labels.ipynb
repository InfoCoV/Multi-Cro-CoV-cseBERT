{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline training on full features including content"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import Normalizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Data paths\n",
    "TRAIN = \"../../data/prepared/full_train_df.pkl\"\n",
    "VAL = \"../../data/prepared/full_val_df.pkl\"\n",
    "TEST = \"../../data/prepared/full_test_df.pkl\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_df = pd.read_pickle(TRAIN)\n",
    "train_df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159544 entries, 0 to 173184\n",
      "Columns: 819 entries, id_str to 767\n",
      "dtypes: float32(768), float64(43), int64(7), object(1)\n",
      "memory usage: 530.7+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>entities.urls</th>\n",
       "      <th>entities.media</th>\n",
       "      <th>user_in_net</th>\n",
       "      <th>has_covid_keyword</th>\n",
       "      <th>tweets_keywords_3_in_degree</th>\n",
       "      <th>tweets_keywords_3_out_degree</th>\n",
       "      <th>tweets_keywords_3_in_strength</th>\n",
       "      <th>tweets_keywords_3_out_strength</th>\n",
       "      <th>tweets_keywords_3_eigenvector_in</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1339076855064915968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.206248</td>\n",
       "      <td>-0.375587</td>\n",
       "      <td>0.994688</td>\n",
       "      <td>0.944173</td>\n",
       "      <td>-0.180504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065715</td>\n",
       "      <td>-0.392403</td>\n",
       "      <td>-0.265053</td>\n",
       "      <td>-0.388531</td>\n",
       "      <td>-0.226297</td>\n",
       "      <td>-0.222182</td>\n",
       "      <td>0.781448</td>\n",
       "      <td>-0.242079</td>\n",
       "      <td>-0.309126</td>\n",
       "      <td>0.046210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1337506645904142336</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.693304</td>\n",
       "      <td>2.200119</td>\n",
       "      <td>0.948712</td>\n",
       "      <td>0.954298</td>\n",
       "      <td>-0.180504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186057</td>\n",
       "      <td>-0.259318</td>\n",
       "      <td>-0.006660</td>\n",
       "      <td>-0.345143</td>\n",
       "      <td>-0.380387</td>\n",
       "      <td>-0.266276</td>\n",
       "      <td>0.508922</td>\n",
       "      <td>-0.029825</td>\n",
       "      <td>-0.168484</td>\n",
       "      <td>-0.183772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1335934602532298752</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.647823</td>\n",
       "      <td>-0.651175</td>\n",
       "      <td>-0.967028</td>\n",
       "      <td>-0.954585</td>\n",
       "      <td>-0.180504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.377129</td>\n",
       "      <td>-0.029135</td>\n",
       "      <td>0.307227</td>\n",
       "      <td>-0.189083</td>\n",
       "      <td>-0.166380</td>\n",
       "      <td>-0.324002</td>\n",
       "      <td>0.719398</td>\n",
       "      <td>-0.213774</td>\n",
       "      <td>-0.615862</td>\n",
       "      <td>-0.176414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1334842452096786432</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.647823</td>\n",
       "      <td>-0.651175</td>\n",
       "      <td>-0.967028</td>\n",
       "      <td>-0.954585</td>\n",
       "      <td>-0.180504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.631918</td>\n",
       "      <td>0.676647</td>\n",
       "      <td>0.148769</td>\n",
       "      <td>-0.047230</td>\n",
       "      <td>-0.288221</td>\n",
       "      <td>-0.551410</td>\n",
       "      <td>0.326829</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>-0.007832</td>\n",
       "      <td>-0.264898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1333647712064057088</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.647823</td>\n",
       "      <td>-0.651175</td>\n",
       "      <td>-0.967028</td>\n",
       "      <td>-0.954585</td>\n",
       "      <td>-0.180504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.927304</td>\n",
       "      <td>0.655230</td>\n",
       "      <td>0.536625</td>\n",
       "      <td>-0.184766</td>\n",
       "      <td>-0.001629</td>\n",
       "      <td>-0.590369</td>\n",
       "      <td>0.995412</td>\n",
       "      <td>-0.092071</td>\n",
       "      <td>-0.069974</td>\n",
       "      <td>-0.182760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 819 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str  entities.urls  entities.media  user_in_net  \\\n",
       "0  1339076855064915968              0               0            0   \n",
       "1  1337506645904142336              1               0            0   \n",
       "2  1335934602532298752              1               0            0   \n",
       "3  1334842452096786432              0               1            0   \n",
       "5  1333647712064057088              0               1            0   \n",
       "\n",
       "   has_covid_keyword  tweets_keywords_3_in_degree  \\\n",
       "0                  0                    -0.206248   \n",
       "1                  0                     1.693304   \n",
       "2                  1                    -0.647823   \n",
       "3                  0                    -0.647823   \n",
       "5                  0                    -0.647823   \n",
       "\n",
       "   tweets_keywords_3_out_degree  tweets_keywords_3_in_strength  \\\n",
       "0                     -0.375587                       0.994688   \n",
       "1                      2.200119                       0.948712   \n",
       "2                     -0.651175                      -0.967028   \n",
       "3                     -0.651175                      -0.967028   \n",
       "5                     -0.651175                      -0.967028   \n",
       "\n",
       "   tweets_keywords_3_out_strength  tweets_keywords_3_eigenvector_in  ...  \\\n",
       "0                        0.944173                         -0.180504  ...   \n",
       "1                        0.954298                         -0.180504  ...   \n",
       "2                       -0.954585                         -0.180504  ...   \n",
       "3                       -0.954585                         -0.180504  ...   \n",
       "5                       -0.954585                         -0.180504  ...   \n",
       "\n",
       "        758       759       760       761       762       763       764  \\\n",
       "0 -0.065715 -0.392403 -0.265053 -0.388531 -0.226297 -0.222182  0.781448   \n",
       "1 -0.186057 -0.259318 -0.006660 -0.345143 -0.380387 -0.266276  0.508922   \n",
       "2 -0.377129 -0.029135  0.307227 -0.189083 -0.166380 -0.324002  0.719398   \n",
       "3 -0.631918  0.676647  0.148769 -0.047230 -0.288221 -0.551410  0.326829   \n",
       "5 -0.927304  0.655230  0.536625 -0.184766 -0.001629 -0.590369  0.995412   \n",
       "\n",
       "        765       766       767  \n",
       "0 -0.242079 -0.309126  0.046210  \n",
       "1 -0.029825 -0.168484 -0.183772  \n",
       "2 -0.213774 -0.615862 -0.176414  \n",
       "3  0.007760 -0.007832 -0.264898  \n",
       "5 -0.092071 -0.069974 -0.182760  \n",
       "\n",
       "[5 rows x 819 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_df_labels = train_df.retweet_label\n",
    "train_df.drop([\"retweet_label\", \"id_str\"], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "val_df = pd.read_pickle(VAL)\n",
    "val_df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19943 entries, 173185 to 194714\n",
      "Columns: 819 entries, id_str to 767\n",
      "dtypes: float32(768), float64(43), int64(7), object(1)\n",
      "memory usage: 66.3+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "val_df_labels = val_df.retweet_label\n",
    "val_df.drop([\"retweet_label\", \"id_str\"], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "test_df = pd.read_pickle(TEST)\n",
    "test_df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19944 entries, 194715 to 214669\n",
      "Columns: 819 entries, id_str to 767\n",
      "dtypes: float32(768), float64(43), int64(7), object(1)\n",
      "memory usage: 66.3+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "test_df_labels = test_df.retweet_label\n",
    "test_df.drop([\"retweet_label\", \"id_str\"], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Content vector scaling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "vec_cols = list(range(768))\n",
    "train_df[vec_cols].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.195360</td>\n",
       "      <td>0.095220</td>\n",
       "      <td>-0.352850</td>\n",
       "      <td>0.146493</td>\n",
       "      <td>0.079543</td>\n",
       "      <td>-0.268018</td>\n",
       "      <td>-0.152660</td>\n",
       "      <td>-0.399202</td>\n",
       "      <td>0.242943</td>\n",
       "      <td>0.348565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333801</td>\n",
       "      <td>0.024535</td>\n",
       "      <td>0.040960</td>\n",
       "      <td>-0.213138</td>\n",
       "      <td>-0.340657</td>\n",
       "      <td>-0.283257</td>\n",
       "      <td>0.437981</td>\n",
       "      <td>-0.097761</td>\n",
       "      <td>-0.250533</td>\n",
       "      <td>-0.167678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.293173</td>\n",
       "      <td>0.214114</td>\n",
       "      <td>0.233547</td>\n",
       "      <td>0.254018</td>\n",
       "      <td>0.187463</td>\n",
       "      <td>0.336944</td>\n",
       "      <td>0.167259</td>\n",
       "      <td>0.312014</td>\n",
       "      <td>0.318916</td>\n",
       "      <td>0.315775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337480</td>\n",
       "      <td>0.242701</td>\n",
       "      <td>0.379640</td>\n",
       "      <td>0.211717</td>\n",
       "      <td>0.230099</td>\n",
       "      <td>0.231490</td>\n",
       "      <td>0.516731</td>\n",
       "      <td>0.362651</td>\n",
       "      <td>0.217527</td>\n",
       "      <td>0.292303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.193549</td>\n",
       "      <td>-0.862558</td>\n",
       "      <td>-1.433369</td>\n",
       "      <td>-1.287081</td>\n",
       "      <td>-0.862269</td>\n",
       "      <td>-2.027415</td>\n",
       "      <td>-1.076601</td>\n",
       "      <td>-1.630700</td>\n",
       "      <td>-1.594843</td>\n",
       "      <td>-1.052173</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.922168</td>\n",
       "      <td>-1.079849</td>\n",
       "      <td>-1.997620</td>\n",
       "      <td>-1.542530</td>\n",
       "      <td>-1.496642</td>\n",
       "      <td>-1.311073</td>\n",
       "      <td>-3.092209</td>\n",
       "      <td>-2.276905</td>\n",
       "      <td>-1.255560</td>\n",
       "      <td>-1.746912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000639</td>\n",
       "      <td>-0.042778</td>\n",
       "      <td>-0.511164</td>\n",
       "      <td>-0.014581</td>\n",
       "      <td>-0.040123</td>\n",
       "      <td>-0.491702</td>\n",
       "      <td>-0.260796</td>\n",
       "      <td>-0.627653</td>\n",
       "      <td>0.045554</td>\n",
       "      <td>0.145942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.565730</td>\n",
       "      <td>-0.134558</td>\n",
       "      <td>-0.192809</td>\n",
       "      <td>-0.353925</td>\n",
       "      <td>-0.490374</td>\n",
       "      <td>-0.446420</td>\n",
       "      <td>0.103474</td>\n",
       "      <td>-0.325314</td>\n",
       "      <td>-0.394385</td>\n",
       "      <td>-0.358993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.178249</td>\n",
       "      <td>0.092149</td>\n",
       "      <td>-0.354339</td>\n",
       "      <td>0.156912</td>\n",
       "      <td>0.081831</td>\n",
       "      <td>-0.279836</td>\n",
       "      <td>-0.155351</td>\n",
       "      <td>-0.431011</td>\n",
       "      <td>0.264410</td>\n",
       "      <td>0.358412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328650</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.073178</td>\n",
       "      <td>-0.209669</td>\n",
       "      <td>-0.327011</td>\n",
       "      <td>-0.286031</td>\n",
       "      <td>0.392544</td>\n",
       "      <td>-0.078316</td>\n",
       "      <td>-0.251108</td>\n",
       "      <td>-0.163843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.376910</td>\n",
       "      <td>0.240091</td>\n",
       "      <td>-0.196517</td>\n",
       "      <td>0.321197</td>\n",
       "      <td>0.194621</td>\n",
       "      <td>-0.063111</td>\n",
       "      <td>-0.049406</td>\n",
       "      <td>-0.196222</td>\n",
       "      <td>0.460196</td>\n",
       "      <td>0.557124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105623</td>\n",
       "      <td>0.166766</td>\n",
       "      <td>0.295857</td>\n",
       "      <td>-0.066293</td>\n",
       "      <td>-0.183453</td>\n",
       "      <td>-0.126617</td>\n",
       "      <td>0.730486</td>\n",
       "      <td>0.142456</td>\n",
       "      <td>-0.105713</td>\n",
       "      <td>0.031476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.780094</td>\n",
       "      <td>0.975826</td>\n",
       "      <td>1.108052</td>\n",
       "      <td>1.300397</td>\n",
       "      <td>1.140064</td>\n",
       "      <td>1.299382</td>\n",
       "      <td>1.041010</td>\n",
       "      <td>1.164399</td>\n",
       "      <td>1.753418</td>\n",
       "      <td>2.136066</td>\n",
       "      <td>...</td>\n",
       "      <td>1.218108</td>\n",
       "      <td>1.140285</td>\n",
       "      <td>2.073954</td>\n",
       "      <td>0.858104</td>\n",
       "      <td>0.673883</td>\n",
       "      <td>0.758497</td>\n",
       "      <td>2.970299</td>\n",
       "      <td>1.877951</td>\n",
       "      <td>0.836245</td>\n",
       "      <td>1.073741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0              1              2              3    \\\n",
       "count  159544.000000  159544.000000  159544.000000  159544.000000   \n",
       "mean        0.195360       0.095220      -0.352850       0.146493   \n",
       "std         0.293173       0.214114       0.233547       0.254018   \n",
       "min        -1.193549      -0.862558      -1.433369      -1.287081   \n",
       "25%        -0.000639      -0.042778      -0.511164      -0.014581   \n",
       "50%         0.178249       0.092149      -0.354339       0.156912   \n",
       "75%         0.376910       0.240091      -0.196517       0.321197   \n",
       "max         1.780094       0.975826       1.108052       1.300397   \n",
       "\n",
       "                 4              5              6              7    \\\n",
       "count  159544.000000  159544.000000  159544.000000  159544.000000   \n",
       "mean        0.079543      -0.268018      -0.152660      -0.399202   \n",
       "std         0.187463       0.336944       0.167259       0.312014   \n",
       "min        -0.862269      -2.027415      -1.076601      -1.630700   \n",
       "25%        -0.040123      -0.491702      -0.260796      -0.627653   \n",
       "50%         0.081831      -0.279836      -0.155351      -0.431011   \n",
       "75%         0.194621      -0.063111      -0.049406      -0.196222   \n",
       "max         1.140064       1.299382       1.041010       1.164399   \n",
       "\n",
       "                 8              9    ...            758            759  \\\n",
       "count  159544.000000  159544.000000  ...  159544.000000  159544.000000   \n",
       "mean        0.242943       0.348565  ...      -0.333801       0.024535   \n",
       "std         0.318916       0.315775  ...       0.337480       0.242701   \n",
       "min        -1.594843      -1.052173  ...      -1.922168      -1.079849   \n",
       "25%         0.045554       0.145942  ...      -0.565730      -0.134558   \n",
       "50%         0.264410       0.358412  ...      -0.328650       0.011230   \n",
       "75%         0.460196       0.557124  ...      -0.105623       0.166766   \n",
       "max         1.753418       2.136066  ...       1.218108       1.140285   \n",
       "\n",
       "                 760            761            762            763  \\\n",
       "count  159544.000000  159544.000000  159544.000000  159544.000000   \n",
       "mean        0.040960      -0.213138      -0.340657      -0.283257   \n",
       "std         0.379640       0.211717       0.230099       0.231490   \n",
       "min        -1.997620      -1.542530      -1.496642      -1.311073   \n",
       "25%        -0.192809      -0.353925      -0.490374      -0.446420   \n",
       "50%         0.073178      -0.209669      -0.327011      -0.286031   \n",
       "75%         0.295857      -0.066293      -0.183453      -0.126617   \n",
       "max         2.073954       0.858104       0.673883       0.758497   \n",
       "\n",
       "                 764            765            766            767  \n",
       "count  159544.000000  159544.000000  159544.000000  159544.000000  \n",
       "mean        0.437981      -0.097761      -0.250533      -0.167678  \n",
       "std         0.516731       0.362651       0.217527       0.292303  \n",
       "min        -3.092209      -2.276905      -1.255560      -1.746912  \n",
       "25%         0.103474      -0.325314      -0.394385      -0.358993  \n",
       "50%         0.392544      -0.078316      -0.251108      -0.163843  \n",
       "75%         0.730486       0.142456      -0.105713       0.031476  \n",
       "max         2.970299       1.877951       0.836245       1.073741  \n",
       "\n",
       "[8 rows x 768 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "scaler = Normalizer()\n",
    "transformed = scaler.fit_transform(train_df[vec_cols].values)\n",
    "train_df[vec_cols] = transformed\n",
    "\n",
    "transformed_val = scaler.transform(val_df[vec_cols].values)\n",
    "val_df[vec_cols] = transformed_val\n",
    "\n",
    "transformed_test = scaler.transform(test_df[vec_cols].values)\n",
    "test_df[vec_cols] = transformed_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "train_df[vec_cols].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "      <td>159544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>-0.028580</td>\n",
       "      <td>0.011676</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>-0.022028</td>\n",
       "      <td>-0.012424</td>\n",
       "      <td>-0.032978</td>\n",
       "      <td>0.020101</td>\n",
       "      <td>0.028570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026178</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>-0.017256</td>\n",
       "      <td>-0.027182</td>\n",
       "      <td>-0.022219</td>\n",
       "      <td>0.035228</td>\n",
       "      <td>-0.007656</td>\n",
       "      <td>-0.020290</td>\n",
       "      <td>-0.012839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022639</td>\n",
       "      <td>0.016913</td>\n",
       "      <td>0.018773</td>\n",
       "      <td>0.020016</td>\n",
       "      <td>0.015010</td>\n",
       "      <td>0.026821</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>0.025655</td>\n",
       "      <td>0.025218</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>0.029669</td>\n",
       "      <td>0.016981</td>\n",
       "      <td>0.018152</td>\n",
       "      <td>0.017773</td>\n",
       "      <td>0.040105</td>\n",
       "      <td>0.028283</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>0.022753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.080297</td>\n",
       "      <td>-0.065725</td>\n",
       "      <td>-0.109652</td>\n",
       "      <td>-0.092831</td>\n",
       "      <td>-0.062930</td>\n",
       "      <td>-0.143057</td>\n",
       "      <td>-0.080418</td>\n",
       "      <td>-0.123465</td>\n",
       "      <td>-0.102206</td>\n",
       "      <td>-0.075590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125459</td>\n",
       "      <td>-0.083214</td>\n",
       "      <td>-0.133192</td>\n",
       "      <td>-0.101022</td>\n",
       "      <td>-0.109637</td>\n",
       "      <td>-0.090948</td>\n",
       "      <td>-0.175592</td>\n",
       "      <td>-0.149472</td>\n",
       "      <td>-0.100577</td>\n",
       "      <td>-0.115395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.003482</td>\n",
       "      <td>-0.041618</td>\n",
       "      <td>-0.001186</td>\n",
       "      <td>-0.003256</td>\n",
       "      <td>-0.039989</td>\n",
       "      <td>-0.021262</td>\n",
       "      <td>-0.052149</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.011660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043702</td>\n",
       "      <td>-0.011015</td>\n",
       "      <td>-0.015577</td>\n",
       "      <td>-0.028709</td>\n",
       "      <td>-0.039282</td>\n",
       "      <td>-0.035115</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>-0.026308</td>\n",
       "      <td>-0.032005</td>\n",
       "      <td>-0.028310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.014484</td>\n",
       "      <td>0.007532</td>\n",
       "      <td>-0.028875</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>-0.022661</td>\n",
       "      <td>-0.012449</td>\n",
       "      <td>-0.035135</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>0.029054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026761</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>-0.017030</td>\n",
       "      <td>-0.026397</td>\n",
       "      <td>-0.023177</td>\n",
       "      <td>0.032194</td>\n",
       "      <td>-0.006395</td>\n",
       "      <td>-0.020329</td>\n",
       "      <td>-0.013188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.030071</td>\n",
       "      <td>0.019347</td>\n",
       "      <td>-0.015760</td>\n",
       "      <td>0.025681</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>-0.005066</td>\n",
       "      <td>-0.003966</td>\n",
       "      <td>-0.015423</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.045743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008714</td>\n",
       "      <td>0.013302</td>\n",
       "      <td>0.024081</td>\n",
       "      <td>-0.005349</td>\n",
       "      <td>-0.014919</td>\n",
       "      <td>-0.010470</td>\n",
       "      <td>0.059403</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>-0.008487</td>\n",
       "      <td>0.002606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.124338</td>\n",
       "      <td>0.069053</td>\n",
       "      <td>0.066742</td>\n",
       "      <td>0.091264</td>\n",
       "      <td>0.083130</td>\n",
       "      <td>0.091769</td>\n",
       "      <td>0.077764</td>\n",
       "      <td>0.081185</td>\n",
       "      <td>0.117348</td>\n",
       "      <td>0.164405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085552</td>\n",
       "      <td>0.074494</td>\n",
       "      <td>0.123961</td>\n",
       "      <td>0.064772</td>\n",
       "      <td>0.053168</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>0.210355</td>\n",
       "      <td>0.127449</td>\n",
       "      <td>0.065561</td>\n",
       "      <td>0.090006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0              1              2              3    \\\n",
       "count  159544.000000  159544.000000  159544.000000  159544.000000   \n",
       "mean        0.015200       0.007507      -0.028580       0.011676   \n",
       "std         0.022639       0.016913       0.018773       0.020016   \n",
       "min        -0.080297      -0.065725      -0.109652      -0.092831   \n",
       "25%        -0.000053      -0.003482      -0.041618      -0.001186   \n",
       "50%         0.014484       0.007532      -0.028875       0.012569   \n",
       "75%         0.030071       0.019347      -0.015760       0.025681   \n",
       "max         0.124338       0.069053       0.066742       0.091264   \n",
       "\n",
       "                 4              5              6              7    \\\n",
       "count  159544.000000  159544.000000  159544.000000  159544.000000   \n",
       "mean        0.006295      -0.022028      -0.012424      -0.032978   \n",
       "std         0.015010       0.026821       0.013482       0.025655   \n",
       "min        -0.062930      -0.143057      -0.080418      -0.123465   \n",
       "25%        -0.003256      -0.039989      -0.021262      -0.052149   \n",
       "50%         0.006594      -0.022661      -0.012449      -0.035135   \n",
       "75%         0.015603      -0.005066      -0.003966      -0.015423   \n",
       "max         0.083130       0.091769       0.077764       0.081185   \n",
       "\n",
       "                 8              9    ...            758            759  \\\n",
       "count  159544.000000  159544.000000  ...  159544.000000  159544.000000   \n",
       "mean        0.020101       0.028570  ...      -0.026178       0.001430   \n",
       "std         0.025218       0.025490  ...       0.025914       0.018903   \n",
       "min        -0.102206      -0.075590  ...      -0.125459      -0.083214   \n",
       "25%         0.003675       0.011660  ...      -0.043702      -0.011015   \n",
       "50%         0.021636       0.029054  ...      -0.026761       0.000913   \n",
       "75%         0.037736       0.045743  ...      -0.008714       0.013302   \n",
       "max         0.117348       0.164405  ...       0.085552       0.074494   \n",
       "\n",
       "                 760            761            762            763  \\\n",
       "count  159544.000000  159544.000000  159544.000000  159544.000000   \n",
       "mean        0.003647      -0.017256      -0.027182      -0.022219   \n",
       "std         0.029669       0.016981       0.018152       0.017773   \n",
       "min        -0.133192      -0.101022      -0.109637      -0.090948   \n",
       "25%        -0.015577      -0.028709      -0.039282      -0.035115   \n",
       "50%         0.005967      -0.017030      -0.026397      -0.023177   \n",
       "75%         0.024081      -0.005349      -0.014919      -0.010470   \n",
       "max         0.123961       0.064772       0.053168       0.053977   \n",
       "\n",
       "                 764            765            766            767  \n",
       "count  159544.000000  159544.000000  159544.000000  159544.000000  \n",
       "mean        0.035228      -0.007656      -0.020290      -0.012839  \n",
       "std         0.040105       0.028283       0.017467       0.022753  \n",
       "min        -0.175592      -0.149472      -0.100577      -0.115395  \n",
       "25%         0.008446      -0.026308      -0.032005      -0.028310  \n",
       "50%         0.032194      -0.006395      -0.020329      -0.013188  \n",
       "75%         0.059403       0.011611      -0.008487       0.002606  \n",
       "max         0.210355       0.127449       0.065561       0.090006  \n",
       "\n",
       "[8 rows x 768 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "clf = MLPClassifier(\n",
    "    max_iter=50,\n",
    "    hidden_layer_sizes=(512,),\n",
    "    random_state=1,\n",
    "    verbose=True,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=5,\n",
    "    learning_rate_init=0.001,\n",
    "    batch_size=256,\n",
    "    alpha=0.001)\n",
    "clf.fit(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 1, loss = 0.60246838\n",
      "Validation score: 0.692510\n",
      "Iteration 2, loss = 0.58407648\n",
      "Validation score: 0.691570\n",
      "Iteration 3, loss = 0.57670078\n",
      "Validation score: 0.691069\n",
      "Iteration 4, loss = 0.57134825\n",
      "Validation score: 0.696521\n",
      "Iteration 5, loss = 0.56624809\n",
      "Validation score: 0.693012\n",
      "Iteration 6, loss = 0.56291106\n",
      "Validation score: 0.697462\n",
      "Iteration 7, loss = 0.55870844\n",
      "Validation score: 0.697399\n",
      "Iteration 8, loss = 0.55490506\n",
      "Validation score: 0.692009\n",
      "Iteration 9, loss = 0.55175634\n",
      "Validation score: 0.696396\n",
      "Iteration 10, loss = 0.54786775\n",
      "Validation score: 0.699091\n",
      "Iteration 11, loss = 0.54371448\n",
      "Validation score: 0.694202\n",
      "Iteration 12, loss = 0.54055150\n",
      "Validation score: 0.692636\n",
      "Iteration 13, loss = 0.53717560\n",
      "Validation score: 0.695080\n",
      "Iteration 14, loss = 0.53317858\n",
      "Validation score: 0.697587\n",
      "Iteration 15, loss = 0.52958391\n",
      "Validation score: 0.693952\n",
      "Iteration 16, loss = 0.52558038\n",
      "Validation score: 0.693137\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.001, batch_size=256, early_stopping=True,\n",
       "              hidden_layer_sizes=(512,), max_iter=50, n_iter_no_change=5,\n",
       "              random_state=1, verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "clf.best_validation_score_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6990911939830774"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "clf.score(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7266835481121195"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "clf.score(val_df.values, val_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6893646893646893"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "val_predictions = clf.predict(val_df.values)\n",
    "val_predictions.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(19943,)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "out = classification_report(val_df_labels.values, val_predictions, output_dict=False)\n",
    "print(out)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73     10954\n",
      "           1       0.68      0.59      0.63      8989\n",
      "\n",
      "    accuracy                           0.69     19943\n",
      "   macro avg       0.69      0.68      0.68     19943\n",
      "weighted avg       0.69      0.69      0.69     19943\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLP Classifier (2)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "clf_2 = MLPClassifier(\n",
    "    max_iter=50,\n",
    "    hidden_layer_sizes=(1000,50,30),\n",
    "    random_state=1,\n",
    "    verbose=True,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=5,\n",
    "    learning_rate_init=0.001,\n",
    "    batch_size=32,\n",
    "    alpha=0.001)\n",
    "clf_2.fit(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 1, loss = 0.61317215\n",
      "Validation score: 0.688750\n",
      "Iteration 2, loss = 0.59969468\n",
      "Validation score: 0.687120\n",
      "Iteration 3, loss = 0.59409519\n",
      "Validation score: 0.690505\n",
      "Iteration 4, loss = 0.59036136\n",
      "Validation score: 0.691319\n",
      "Iteration 5, loss = 0.58741700\n",
      "Validation score: 0.689251\n",
      "Iteration 6, loss = 0.58474160\n",
      "Validation score: 0.687935\n",
      "Iteration 7, loss = 0.58276091\n",
      "Validation score: 0.692761\n",
      "Iteration 8, loss = 0.58098337\n",
      "Validation score: 0.692259\n",
      "Iteration 9, loss = 0.57954971\n",
      "Validation score: 0.696396\n",
      "Iteration 10, loss = 0.57838327\n",
      "Validation score: 0.693137\n",
      "Iteration 11, loss = 0.57710035\n",
      "Validation score: 0.693012\n",
      "Iteration 12, loss = 0.57605357\n",
      "Validation score: 0.697211\n",
      "Iteration 13, loss = 0.57521887\n",
      "Validation score: 0.693137\n",
      "Iteration 14, loss = 0.57445013\n",
      "Validation score: 0.697336\n",
      "Iteration 15, loss = 0.57356258\n",
      "Validation score: 0.696960\n",
      "Iteration 16, loss = 0.57316001\n",
      "Validation score: 0.696772\n",
      "Iteration 17, loss = 0.57201924\n",
      "Validation score: 0.694328\n",
      "Iteration 18, loss = 0.57193100\n",
      "Validation score: 0.699154\n",
      "Iteration 19, loss = 0.57109008\n",
      "Validation score: 0.695581\n",
      "Iteration 20, loss = 0.57037419\n",
      "Validation score: 0.693388\n",
      "Iteration 21, loss = 0.57035913\n",
      "Validation score: 0.696584\n",
      "Iteration 22, loss = 0.57005167\n",
      "Validation score: 0.699154\n",
      "Iteration 23, loss = 0.56909485\n",
      "Validation score: 0.694767\n",
      "Iteration 24, loss = 0.56863123\n",
      "Validation score: 0.693513\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.001, batch_size=32, early_stopping=True,\n",
       "              hidden_layer_sizes=(1000, 50, 30), max_iter=50,\n",
       "              n_iter_no_change=5, random_state=1, verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "clf_2.best_validation_score_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6991538702601066"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "clf_2.score(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7145426966855538"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "clf_2.score(val_df.values, val_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6861054003911147"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "val_predictions = clf_2.predict(val_df.values)\n",
    "val_predictions.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(19943,)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "out = classification_report(val_df_labels.values, val_predictions, output_dict=False)\n",
    "print(out)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73     10954\n",
      "           1       0.68      0.58      0.62      8989\n",
      "\n",
      "    accuracy                           0.69     19943\n",
      "   macro avg       0.68      0.68      0.68     19943\n",
      "weighted avg       0.69      0.69      0.68     19943\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=25,\n",
    "    min_samples_split=0.00002,\n",
    "    min_samples_leaf=0.00002,\n",
    "    random_state=1,\n",
    "    verbose=True,\n",
    "    n_jobs=-1,\n",
    "    max_samples=0.4,\n",
    "    max_features=0.2,\n",
    "    oob_score=True,\n",
    "    class_weight=\"balanced\",\n",
    "    min_impurity_decrease=0.00008\n",
    "    )\n",
    "rf.fit(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=25, max_features=0.2,\n",
       "                       max_samples=0.4, min_impurity_decrease=8e-05,\n",
       "                       min_samples_leaf=2e-05, min_samples_split=2e-05,\n",
       "                       n_estimators=200, n_jobs=-1, oob_score=True,\n",
       "                       random_state=1, verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "rf.score(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=24)]: Done 200 out of 200 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8533696033696033"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "rf.score(val_df.values, val_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6843503986361129"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "rf_val_predictions = rf.predict(val_df.values)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 152 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=24)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "out = classification_report(val_df_labels.values, rf_val_predictions, output_dict=False, digits=3)\n",
    "print(out)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.698     0.749     0.723     10954\n",
      "           1      0.664     0.606     0.634      8989\n",
      "\n",
      "    accuracy                          0.684     19943\n",
      "   macro avg      0.681     0.677     0.678     19943\n",
      "weighted avg      0.683     0.684     0.683     19943\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dummy classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "s_dummy = DummyClassifier(strategy=\"stratified\", random_state=1)\n",
    "s_dummy.fit(train_df.values, train_df_labels.values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=1, strategy='stratified')"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "dummy_val_predictions = s_dummy.predict(val_df.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "out = classification_report(val_df_labels.values, dummy_val_predictions, output_dict=False)\n",
    "print(out)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.58      0.56     10954\n",
      "           1       0.45      0.41      0.43      8989\n",
      "\n",
      "    accuracy                           0.51     19943\n",
      "   macro avg       0.50      0.50      0.50     19943\n",
      "weighted avg       0.50      0.51      0.50     19943\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15267cfa9f25b6ca31c547cf72167e122f3ae1ce2ab22c3e1aaf6fd39ae5e059"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('infocov_retweet': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}